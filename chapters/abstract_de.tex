\chapter*{Kurzfassung}
\vspace{-1cm}
Informationstechnologien helfen uns unsere digitalen Inhalte (Dokumente, Bilder, etc.) leicht zu verwalten.
Dies ist der Grund f\"{u}r die zur Zeit bemerkenswerte digitale Datenproduktion.
Allerdings, werden dadurch viele technische, sowie auch soziale Probleme, die mit der Sicherheit, Langzeitarchivierung und Zugriff zu tun haben, verursacht.

Digitale Langzeitarchivierung versucht genau diese Probleme zu l\"{o}sen, die mit Hardware- und Softwareveralterung zu tun haben, sowie auch den Zugriff f\"{u}r l\"{a}ngere Zeitr\"{a}ume zu garantieren.
Unter den zahlreichen Optionen stechen Konzepte wie Bit-stream und logische Pr\"{a}servierung mit deren unterschiedlichen Auspr\"{a}gungen besonders heraus.

Damit man eine eine gute Entscheidung \"{u}ber die potentielle Alternativen oder Pr\"{a}servierungsaktionen, die man auf eine digitale Kollektion durchf\"{u}hren oder nicht durchf\"{u}hren sollte, treffen kann, muss man ein Planungsprozess befolgen.
Dies ist ein komplexer Prozess, der ziemlich zeitraubend ist, der aber als Ergebnis ein Pr\"{a}servierungsplan hat.
Der Plan spezifiziert konkrete Aktionen f\"{u}r die Pr\"{a}servierung von einer Menge von digitalen Objekten und umfasst potentielle Alternativen und Gr\"{u}nde f\"{u}r die getroffene Entscheidung.
Da die zu bewahrenden Kollektionen in der Praxis ziemlich gro{\ss} sind (tera oder sogar petabytes, bestehend aus Millionen von Objekten), ist es nicht m\"{o}glich einen Plan zu erstellen, der auf Experimente \"{u}ber die ganze Kollektion basiert.
Aus diesem Grund ist die Erstellung einer umfassenden Beschreibung der Kollektion unbestreitbar einer der wichtigsten Teile des Plannungsprozesses.
Der Prozess der Erstellung von dieser Beschreibung nennt man Content Profiling.

Generell besteht Content Profiling aus drei Teile; Charakterisierung, Aggregation und Analyse.
Im ersten Schritt wird eine Identifikation der digitalen Objekten durchgef\"{u}hrt, sowie Meta Daten werden extrahiert.
In der Aggregationsphase werden alle gesammelten Daten zusammengefasst, sodass diese in einer kompressierten Form dargestellt werden k\"{o}nnen.
Im letzten Schritt werden interessante Aspekte der Kollektion durch eine tiefgehende Analyse festgestellt und f\"{u}r weitere Behandlung bereitgestellt. 
So wird durch den Content Profiling Prozess eine detaillierte Beschreibung der Daten erfasst, da ein Profil nicht nur aus einfache Messungen, wie Gr\"{o}{\ss}e, Anzahl von Objekten und Formate besteht, aber auch eine ausf\"{u}rliche Ansicht darstellt, die auf jeder beliebigen Charakteristik, oder deren Verteilung, basieren kann.
Wegen des Volumens der Daten, ist die Auswahl von einer kleinen Teilmenge von repr\"{a}sentativen Objekten besonders wichtig.
Daraufbasierend werden Experimente durchgef\"{u}hrt, die Evidenz f\"{u}r die Effektivit\"{a}t und G\"{u}ltigkeit der potentiellen Aktionen bereitstellen.

Es existiert leider nach dem aktuellen Stand der Langzeitarchivierung keine L\"{o}sung, die es erlaubt einen detaillierten Profil von signifikanten Datens\"{a}tzen automatisch zu erstellen, repr\"{a}sentative Teilmengen auszuw\"{a}hlen und diese Informationen in einem semi-strukturierten Format darzustellen.

In dieser Arbeit betrachten wir die existierenden L\"{u}cken im Umfeld von dem Content Profiling und dem Planungprozess.
Der Beitrag dieses Werks besteht darin, eine konzeptionelle L\"{o}sung des Problems, sowie eine Implementierung in Form von einem Prototyp zu erstellen.
Das Prototyp kann auf Kollektionen von vern\"{u}nftigen Gr\"{o}{\ss}en arbeiten und hilft einem, eine tiefgehende Analyse durchzuf\"{u}hren.
Abschlie{\ss}end wird dieses anhand zwei Fallstudien von Datenkollektionen mit signifikanten Volumen evaluiert.

