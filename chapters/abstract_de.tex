\chapter*{Kurzfassung}
\vspace{-1cm}
Informationstechnologien helfen uns, unsere digitalen Inhalte leicht zu verwalten.
Dies ist der Grund f\"{u}r die zur Zeit bemerkenswerte digitale Datenproduktion.
Allerdings, werden dadurch viele technische und soziale Probleme, die mit der Sicherheit, Langzeitarchivierung und Zugriff zu tun haben, verursacht.

Digitale Langzeitarchivierung versucht genau diese Probleme zu l\"{o}sen, die mit Hardware- und Softwareveralterung zu tun haben, sowie auch den zuk\"{u}ntigen Zugriff zu garantieren.

Um eine sinnvolle Entscheidung \"{u}ber die Zukunft von einer digitalen Kollektion zu treffen, muss man einen Planungsprozess befolgen.
Das Ergebnis von diesem komplexen Prozess ist ein Langzeitarchivierungsplan.
Dieser ist ein Artefakt, das die konkrete Aktionen f\"{u}r die Langzeitarchivierung von einer Menge von digitalen Objekten spezifiziert und potentielle Alternativen und Gr\"{u}nde f\"{u}r die getroffene Entscheidung umfasst.
Die Entscheidung basiert auf Wissen \"{u}ber die Inhalte und auf die Ergebnisse von Evaluirungsexperimenten, die auf Beispielobjekte durchgef\"{u}hrt werden.
Aus diesem Grund ist die Erstellung eines Content Profile, das aus einer umfassenden Beschreibung der Kollektion, sowie aus einer kleinen Menge von Beispielobjekten besteht, unbestreitbar entscheidend f\"{u}r einen effektiven Plannungsprozess.

Generell besteht Content Profiling aus drei Teilen: Charakterisierung, Aggregation und Analyse.
Im ersten Schritt wird eine Identifikation der digitalen Objekten durchgef\"{u}hrt und Meta Daten werden extrahiert.
In der Aggregationsphase werden die gesammelten Daten in einer kompressierten Form dargestellt.
Im letzten Schritt werden relevante Aspekte der Kollektion durch eine tiefgehende Analyse festgestellt und f\"{u}r Weiterverabeitung bereitgestellt. 

Experten stehen heutzutage wegen des gro{\ss}en Volumens von Daten vor vielen Herausforderungen. Einerseits ist die Charakterisierung von digitalen Objekten ein umst\"{a}ndlicher und fehelrhafter Prozess. Andererseits ist die Aggregation von den Ausgaben unterschiedlichen Werkzeugen mit komplexen Schemata eine Aufgabe, die Fachkenntnisse von Experten braucht und die schwerf\"{a}llig auf gro{\ss}en Skalen ist.
Das Fehlen einer umfassenden Beschreibung und \"{U}berblick sind oft der Grund f\"{u}r die Auswahl von Zufallsobjekten. Dies f\"{u}hrt zur Selektion von Objekten, die nicht repr\"{a}sentativ sind und kann zur gef\"{a}lschten Experimenten f\"{u}hren.

Nach dem aktuellen Stand der Langzeitarchivierung existieren keine L\"{o}sungen, die es erlauben einen detaillierten Profil von signifikanten Datens\"{a}tzen automatisch zu erstellen, repr\"{a}sentative Teilmengen auszuw\"{a}hlen und in einem semi-strukturierten Format darzustellen.

In dieser Arbeit betrachten wir die existierenden L\"{u}cken im Bereich des Content Profiling und des Planungprozess.
Der Beitrag dieser Arbeit besteht darin, eine konzeptionelle L\"{o}sung des Problems sowie eine Implementierung in Form eines Prototypen zu erstellen.
Der Prototyp kann auf Kollektionen von substantieller Gr\"{o}{\ss}e arbeiten und hilft bei der tiefgehenden Analyse.
Abschlie{\ss}end wird dieser Prototyp anhand zweier Fallstudien von Datenkollektionen mit signifikanten Volumen evaluiert.

